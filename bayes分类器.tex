\documentclass[12pt, a4paper, oneside]{ctexart}
\usepackage{amsmath, amsthm, amssymb, graphicx,color}
\usepackage[bookmarks=true, colorlinks, citecolor=blue, linkcolor=black]{hyperref}
\usepackage{listings} % 插入代码
\usepackage{pythonhighlight}
\usepackage{hyperref}
% 导言区
\usepackage{tikz}
\usepackage{float}%图片悬浮

\title{bayes分类器笔记}
\author{shwj}
\date{\today}
\begin{document}
\maketitle



\par
参考资料：
\begin{enumerate}
    \item \href{https://www.bilibili.com/video/BV1g7411b7r2}{随机过程 - 华中科技大学} 
\end{enumerate}

\section{Bayesian决策论}
\par 
引例:设$\omega$为随机变量$\omega ={\omega}_1$时为鲈鱼，$\omega ={\omega}_2$时为马哈鱼，频率学派会仅仅依靠先验知识判断$\omega$属于哪种鱼，即依据"地点，季节"的先验知识，来计算出先验概率$P({\omega}_1)$和$P({\omega}_2)$，其中$P({\omega}_1)$+$P({\omega}_2)=1$。但这种策略因为缺少信息只能预测出新样本$\omega = \arg\max\limits_{{\omega}_i}P({\omega}_i)$，它的错误率为$P({\omega}_j)$
\par
bayes决策论的改进是引入观测信息，如鱼的体长$x$，再引入类条件概率密度$p(x|\omega)$，即类别$\omega$的概率密度分布，决策时将$\omega$划入后验概率$P({\omega}_i|x)$中最大的某一类。
\par
类条件概率密度$p(x|{\omega}_i) (i=1,2,\cdots,n)$是可以根据样本对每一类分别计算的。而根据bayes公式有
$$p({\omega}_i|x)=\frac{p({\omega}_i,x)}{p(x)}=\frac{p({\omega}_i|x)P({\omega}_i)}{p(x)}$$
所以贝叶斯决策的目标就是根据训练数据，算出先验概率分布和类条件概率分布
\section{朴素贝叶斯分类器}
\par 
朴素贝叶斯认为各个特征相互独立。设类条件概率为$P(x|{\omega}_i)=P(x_1,x_2,\cdots,x_d|{\omega}_i)$，其中$d$为属性的维度，那么根据独立性假设就有
$$P({\omega}_i|x)=\frac{P({\omega}_i)P(x|{\omega}_i)}{P(x)}=\frac{P({\omega}_i)}{P(x)} \prod_{j=1}^d{P(x_j|{\omega}_i)}$$
通过计算$h^*(x)= \arg\max\limits_{{\omega}_i}P({\omega}_i)\prod_{j=1}^d{P(x_j|{\omega}_i)}$来判断$\omega$属于具体哪一类比如计算
如对某个样本比较比较
\\ P(好瓜)*P(色=青|好)*P(根=青|好)*P(敲=浊|好)*P(含糖率=0.46|好)与
\\ P(坏瓜)*P(色=青|坏)*P(根=青|坏)*P(敲=浊|坏)*P(含糖率=0.46|坏)
的大小来进行分类
\section{贝叶斯分类器分类器}
\newpage
\section{作业}
\subsection{}
\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{homework.png}
    % \caption{}
    % \label{}
\end{figure}
\par 依据$\widehat{P}(c)=\frac{|D_c|+1}{|D|+N}$,先验概率可估计为 
\\ $\widehat{P}(\mbox{好瓜=是})=\frac{8+1}{17+2}=\frac{9}{19}$，$\widehat{P}(\mbox{好瓜=否})=\frac{9+1}{17+2}=\frac{10}{19}$
\\ 利用$\widehat{P}(x_i|c)=\frac{|D_{c,x_i}|+1}{|D_c|+N_i}$可对属性条件概率作出修正:
\\ $\widehat{P}(\mbox{色泽=青绿|好瓜=是})=\frac{3+1}{8+3}=\frac{4}{11}$
\\ $\widehat{P}(\mbox{色泽=青绿|好瓜=否})=\frac{3+1}{9+3}=\frac{1}{3}$
\\ $\widehat{P}(\mbox{根蒂=蜷缩|好瓜=是})=\frac{5+1}{8+3}=\frac{6}{11}$
\\ $\widehat{P}(\mbox{根蒂=蜷缩|好瓜=否})=\frac{3+1}{9+3}=\frac{1}{3}$
\\ $\widehat{P}(\mbox{敲声=浊响|好瓜=是})=\frac{6+1}{8+3}=\frac{7}{11}$
\\ $\widehat{P}(\mbox{敲声=浊响|好瓜=否})=\frac{4+1}{9+3}=\frac{5}{12}$
\\ $\widehat{P}(\mbox{纹理=清晰|好瓜=是})=\frac{7+1}{8+3}=\frac{8}{11}$
\\ $\widehat{P}(\mbox{纹理=清晰|好瓜=否})=\frac{2+1}{9+3}=\frac{1}{4}$
\\ $\widehat{P}(\mbox{脐部=凹陷|好瓜=是})=\frac{5+1}{8+3}=\frac{1}{3}$
\\ $\widehat{P}(\mbox{脐部=凹陷|好瓜=否})=\frac{2+1}{9+3}=\frac{1}{3}$
\\ $\widehat{P}(\mbox{触感=硬滑|好瓜=是})=\frac{6+1}{8+2}=\frac{7}{10}$
\\ $\widehat{P}(\mbox{触感=硬滑|好瓜=否})=\frac{6+1}{9+2}=\frac{7}{11}$
\\ $P(\mbox{密度=0.697|好瓜=是})=\frac{1}{\sqrt{2\pi}\cdot 0.129}\exp(-\frac{(0.697-0.574)^2}{2\cdot {0.129}^2})\approx 1.959$
\\ $P(\mbox{密度=0.697|好瓜=否})=\frac{1}{\sqrt{2\pi}\cdot 0.195}\exp(-\frac{(0.697-0.574)^2}{2\cdot {0.195}^2})\approx 1.203$
\\ $P(\mbox{含糖率=0.460|好瓜=是})=\frac{1}{\sqrt{2\pi}\cdot 0.101}\exp(-\frac{(0.460-0.279)^2}{2\cdot {0.101}^2})\approx 0.788$
\\ $P(\mbox{含糖率=0.460|好瓜=否})=\frac{1}{\sqrt{2\pi}\cdot 0.108}\exp(-\frac{(0.460-0.154)^2}{2\cdot {0.108}^2})\approx 0.066$
\\ 利用朴素贝叶斯分类器有
% $$\widehat{P}(\mbox{好瓜=是})\cdot\widehat{P}(\mbox{色泽=青绿|好瓜=是})\cdot\widehat{P}(\mbox{根蒂=蜷缩|好瓜=是})\cdot \widehat{P}(\mbox{好瓜=是})\cdot \widehat{P}(\mbox{敲声=浊响|好瓜=是})\cdot\widehat{P}(\mbox{纹理=清晰|好瓜=是})\cdot\widehat{P}(\mbox{脐部=凹陷|好瓜=是})\cdot\widehat{P}(\mbox{触感=硬滑|好瓜=是})\cdot P(\mbox{密度=0.697|好瓜=是})\cdot P(\mbox{含糖率=0.460|好瓜=是})$$
\begin{equation}
    \begin{aligned}
        P & (\mbox{好瓜=是}|\boldsymbol{x})= \\
        & \widehat{P}(\mbox{好瓜=是})\cdot\widehat{P}(\mbox{色泽=青绿|好瓜=是})\cdot\widehat{P}(\mbox{根蒂=蜷缩|好瓜=是})\cdot \\
        & \widehat{P}(\mbox{敲声=浊响|好瓜=是})\cdot\widehat{P}(\mbox{纹理=清晰|好瓜=是})\cdot \widehat{P}(\mbox{脐部=凹陷|好瓜=是})\cdot \\
        & \widehat{P}(\mbox{触感=硬滑|好瓜=是})\cdot P(\mbox{密度=0.697|好瓜=是}) \cdot P(\mbox{含糖率=0.460|好瓜=是}) \\
        & =\frac{9408}{439230}\cdot 1.959 \cdot 0.788 \approx 0.033
    \end{aligned}
    \nonumber
\end{equation}
同理可计算得$P(\mbox{好瓜=否}|\boldsymbol{x})=\frac{350}{270864}\cdot 1.203 \cdot 0.066 \approx 1.026\cdot 10^{-4}$
\\ 故将该样本分类为好瓜
\subsection{简述Bayes分类器,朴素贝叶斯分类器,半朴素贝叶斯分类器,Baysian网络之间的的区别和联系}
\par 
设训练集$D$的类标签$c$有$N$种，分别为$\{c_1,c_2,\cdots,c_N\}$；样本属性$\boldsymbol{x}$有$d$维，分别是$(x_1,x_2,\cdots,x_d)$。Bayes分类器通过$D$，计算出先验概率$P(c)$和似然分布（即类条件概率）$P(\boldsymbol{x}|c)$，对于新样本${\boldsymbol{x}}_0$通过$p(c|x_0)=\frac{p(c)P(x_0|c)}{p(x_0)}$来计算后验概率$P(c|{\boldsymbol{x}}_0)$，以此判断${\boldsymbol{x}}_0$的类别$c$
\par
朴素贝叶斯分类器无非就是假设所有属性相互独立时的Bayes分类器，这是因为$P(\boldsymbol{x}|c)$是$d$个属性的联合概率分布，若各属性取值为离散型，则样本空间的元素至少有$2^d$个，需要很大的训练集。朴素贝叶斯分类器认为$P(\boldsymbol{x}|c)=\prod_{i=1}^d{P(x_i|c)}$，这样计算似然时只需要关注每个属性的类先验概率。
\par
半朴素贝叶斯分类器认为朴素贝叶斯分类器的条件独立性的假设过强，例如一个人的数学成绩和物理成绩并不是完全不相关的，但是考虑到计算联合概率又很复杂，所以会作出“独依赖估计”，认为每个属性最多仅依赖其他的一个属性。例如SPODE方法就更进一步地认为$d-1$个属性依赖某个属性，然后通过交叉验证算$d$次的方法，得到该属性。不妨其为设$x_1$，则后验概率可表示为
$$P(c|x)\propto P(c)P(x_1)\prod_{i=2}^d{P(x_i|c,x_1)}$$
\par
Baysian网络是一个结构和参数均可学习的DAG，它的连接表示着属性间的条件独立关系和依赖关系，以此在计算时将$P(\boldsymbol{x})$拆分成若干变量的联合概率。Baysian网络在学习属性间的关系。
\subsection{假设在某个局部地区细胞中正常(\texorpdfstring{${\omega}_1$},) 和异常(\texorpdfstring{${\omega}_2$},) 两类的先验概率为\texorpdfstring{$P({\omega}_1)=0.7$},和\texorpdfstring{$P({\omega}_2)=0.3$},现有一待识别细胞，其观测值为\texorpdfstring{$x$},，从类条件概率密度分布曲线中查得：\texorpdfstring{$P(x|{\omega}_1)=0.4,P(x|{\omega}_2)=0.1$},试用贝叶斯决策对该细胞进行分类。}
$$p({\omega}_1|x)=\frac{p({\omega}_1|x)P({\omega}_1)}{p(x)}=\frac{0.28}{p(x)}$$
$$p({\omega}_2|x)=\frac{p({\omega}_2|x)P({\omega}_2)}{p(x)}=\frac{0.07}{p(x)}$$
得$p({\omega}_1|x)>p({\omega}_2|x)$，所以认为该细胞为${\omega}_1$类，即为正常细胞
\end{document}